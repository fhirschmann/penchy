#!/usr/bin/env python

"""
This is the main entry point for PenchY.

Execute this if you want to run the full PenchY
cycle (deploying jobs, executing jobs, accumulating results).

 .. moduleauthor:: Fabian Hirschmann <fabian@hirschm.net>

 :copyright: PenchY Developers 2011-2012, see AUTHORS
 :license: MIT License, see LICENSE
"""
from __future__ import print_function
import logging
import os
from functools import partial

import argparse

from penchy.server import Server
from penchy.util import load_job, load_config, get_config_attribute, die
from penchy.log import configure_logging


if __name__ == "__main__":
    # Parse the config file
    conf_parser = argparse.ArgumentParser(add_help=False)
    conf_parser.add_argument("-c", "--config",
            action="store", dest="config",
            default=os.path.expanduser("~/.penchyrc"),
            help="config module to use")
    args, _ = conf_parser.parse_known_args()
    try:
        config = load_config(args.config)
    except IOError as e:
        config_err = str(e)
        config = None

    ca = partial(get_config_attribute, config)

    # Parse all other options
    parser = argparse.ArgumentParser(
            description=os.linesep.join(__doc__.split(os.linesep)[:-5]),
            parents=[conf_parser])

    log_group = parser.add_mutually_exclusive_group()
    log_group.add_argument("-d", "--debug",
            action="store_const", const=logging.DEBUG,
            dest="loglevel", default=logging.INFO,
            help="print debugging messages")
    log_group.add_argument("-q", "--quiet",
            action="store_const", const=logging.WARNING,
            dest="loglevel", help="suppress most messages")

    parser.add_argument("--logfile",
            action="store", dest="logfile", help="log file to log to",
            default=ca('LOGFILE', None))

    parser.add_argument("-f", "--load-from",
            action="store", dest="load_from",
            help="path or zip to load penchy from on the node")

    parser.add_argument("--skip-apicheck",
            action="store_true", dest="skip_apicheck",
            help="don't check the api of dependencies")

    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument("--check", action="store_true",
            dest="check", help="check a job for validity and exit")
    mode_group.add_argument("--run-locally", action="store_true",
            dest="local", help="test a job by running it locally")
    mode_group.add_argument("--visualize", action="store_true",
            dest="visualize", help="draw a visualization of pipeline dependencies")

    parser.add_argument("job", help="job to execute",
            metavar="job")
    args = parser.parse_args()

    if not config:
        die("Error loading config file from '%s': %s" % (args.config, config_err))

    try:
        job_module = load_job(args.job)
    except Exception as e:
        die("Error loading job '%s: %s" % (args.job, e))
    job = job_module.job

    if not args.skip_apicheck:
        from penchy.apicheck import check_all
        check_all()

    configure_logging(args.loglevel, args.logfile)

    if args.check:
        if job.check():
            print("Check passed")
        else:
            print("Check failed")
    elif args.local:
        compositions = job.compositions_for_node("localhost")
        job.filename = job_module.__file__
        if len(compositions) == 0:
            die("Job has no JVMNodeConfiguration for \"localhost\"")
        for composition in compositions:
            job.run(composition)
    elif args.visualize:
        path = job.visualize()
        print('You can view the visualization of the job here: "{0}"'.format(path))
    else:
        server = Server(config, job_module)
        server.bootstrap_args.extend(['--loglevel', str(args.loglevel)])

        if args.load_from:
            server.bootstrap_args.extend(['--load-from', args.load_from])
        if job.check():
            server.run()
        else:
            print("Check failed, won't executed job.")
